---
title: "A. phalloides RNAseq: Leaderless RiPPs in CA & EU"
author: "Livia Songster"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: flatly
    self_contained: true
    toc: true
    toc_float: true
---

### Data QC

First I uploaded the data to msi from Box using filezilla.

Rough pipeline
 - fastqc
 - fastp trimming
 - multiqc
 - star
 
 
```{r generate_config_file}
# get filenames
filenames <- list.files("D:/Aphalloides_rnaseq_for_leaderless/RAWTRANS/raw_data/201016_AHL2WCDSXY/201016_AHL2WCDSXY",pattern=".gz")

# extract sample ID column without underscores
Sample_ID <- unique(paste0(sapply(strsplit(filenames,split="_"), `[`, 1)))

SampleName <- unique(paste0(sapply(strsplit(filenames,split="_"), `[`, 1),
                            "_",
                            sapply(strsplit(filenames,split="_"), `[`, 2),
                            "_",
                            sapply(strsplit(filenames,split="_"), `[`, 3)))


# make empty config file
config <- as.data.frame(cbind(rep(1:length(SampleName)), SampleName,Sample_ID))

# add dir column to specify output dirs
colnames(config)[1] <- "ArrayTaskID"

# add remaining sample from the rerun folder manually
config[nrow(config)+1,] <- c("39","10745_S87_L001","10745-rerun")

# save output
write.table(config,"slurm_scripts/aphal_rnaseq_config.txt",row.names=FALSE)

```


#### run_fastqc_v2.sh
Below is a slurm script for running fastp and fastqc, using my config file:

Job ID: 31137006  
Cluster: agate  
User/Group: songs005/mdrott  
State: COMPLETED (exit code 0)  
Nodes: 1  
Cores per node: 8  
CPU Utilized: 03:31:40  
CPU Efficiency: 12.41% of 1-04:25:52 core-walltime  
Job Wall-clock time: 03:33:14  
Memory Utilized: 628.33 MB  
Memory Efficiency: 0.48% of 128.00 GB

```{bash fastqc, eval=FALSE}
#!/bin/bash -l
#SBATCH --job-name=fastqc_raw_trim   # Optional job name
#SBATCH --ntasks=2		 # Total number of tasks
#SBATCH --cpus-per-task=4
#SBATCH --mem=128g      # max memory limit
#SBATCH --time=20:00:00   # Walltime limit
#SBATCH --mail-type=begin
#SBATCH --mail-type=end
#SBATCH --mail-user=songs005@umn.edu

# define config file & variables
config=/scratch.global/songs005/aphal_rnaseq/aphal_rnaseq_config.txt

# sample names / prefixes for reads
samplename=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $2}' $config)

# location of raw reads
data=/scratch.global/songs005/aphal_rnaseq/raw_reads

# output dir
dir=/scratch.global/songs005/aphal_rnaseq/raw_reads/fastqc

# make output directory
mkdir -p $dir

# then run QC on the raw reads
fastqc -o $dir/fastqc $data/*.fastq.gz
```

#### run_fastp_v2.sh

For reasons beyond me the config file did not work - it was unable to read the config file properly I think. So instead, I used the same forloop I used for running fastp on F sporo. results below:

<i> Note: after chatting with Mickey, it turns out I was failing to add an essential #SBATCH --array=1-39 command at the beginning of the bash script! </i>


Job ID: 31140982  
Cluster: agate  
User/Group: songs005/mdrott  
State: COMPLETED (exit code 0)  
Nodes: 1  
Cores per node: 8  
CPU Utilized: 10:44:50  
CPU Efficiency: 24.74% of 1-19:26:32 core-walltime  
Job Wall-clock time: 05:25:49  
Memory Utilized: 2.79 GB  
Memory Efficiency: 2.18% of 128.00 GB  

```{bash fastp_trim, eval=FALSE}
#!/bin/bash -l
#SBATCH --job-name=fastp_trim   # Optional job name
#SBATCH --ntasks=2		 # Total number of tasks
#SBATCH --cpus-per-task=4
#SBATCH --mem=128g      # max memory limit
#SBATCH --time=20:00:00   # Walltime limit
#SBATCH --mail-type=begin
#SBATCH --mail-type=end
#SBATCH --mail-user=songs005@umn.edu

# define config file & variables
config=/scratch.global/songs005/aphal_rnaseq/aphal_rnaseq_config.txt

# sample names / prefixes for reads
samplename=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $2}' $config)

# location of raw reads
data=/scratch.global/songs005/aphal_rnaseq/raw_reads

# output dir
dir=/scratch.global/songs005/aphal_rnaseq/trimmed_data

# make output directory
mkdir -p $dir

# run fastp; this will autodetect adapters 
# -c is for base correction based on R1/R2 overlap
# -q is for qualified_quality_phred; minimal acceptable quality value
# -l is for length filtering options; reads shorter than this length will be discarded
# --detect_adapter_for_pe will specifically look for adapters; can result in a slightly more accurate & cleaner trim; slows down script a bit
  
fastp -c -q 10 -l 50 --detect_adapter_for_pe \
  -i $data/${samplename}_R1_001.fastq.gz \
  -I $data/${samplename}_R2_001.fastq.gz \
  -o $dir/${samplename}_trim_R1.fastq.gz \
  -O $dir/${samplename}_trim_R2.fastq.gz \
  --html $dir/${samplename}_trim.fastp.html \
  --json $dir/${samplename}_trim.fastp.json 

# then run QC on these trimmed reads
fastqc -o $dir/fastqc $dir/*.fastq.gz
```

I also ran multiqc on each directory to summarize fastQC results. transferred these to my laptop.

### Hisat2

This took about 40 minutes to run hisat2 for one sample, and another 40 minutes or so to convert the sam to bam and index it.

```{bash test_hisat, eval=FALSE}
# start interactive session
srun -N 1 --ntasks-per-node=16 --mem=60gb --gres=gpu:a40:1 -t 2:00:00 -p interactive-gpu --tmp 100gb --pty bash

# load hisat2 and samtools
$ module load hisat2
$ hisat2 --version
/common/software/install/migrated/hisat2/2.1.0/bin/hisat2-align-s version 2.1.0
64-bit
Built on swan.msi.umn.edu
Tue Sep 19 14:45:21 CDT 2017
Compiler: gcc version 4.4.7 20120313 (Red Hat 4.4.7-18) (GCC)

$ samtools --version
samtools 1.16.1
Using htslib 1.16

# generate index - takes like 30 seconds
hisat2-build reff/10511_Aphal_PT_AllpathsLG_LINKS_jelly_pilon.fna reff/aphal_hisat_index

# test run on one sample
hisat2 -x reff/aphal_hisat_index -1 trimmed_data/10708_S250_L002_trim_R1.fastq.gz -2 trimmed_data/10708_S250_L002_trim_R2.fastq.gz -S test.sam --phred33 --dta -t --rna-strandness RF

# convert
samtools view -uS test.sam | samtools sort -o test.bam
samtools index test.bam


```

#### hisat2_v2.sh

Script for running hisat2 with slurm array:

Job ID: 31307585  
Array Job ID: 31307585_39  
Cluster: agate  
User/Group: songs005/mdrott  
State: COMPLETED (exit code 0)  
Nodes: 1  
Cores per node: 8  
CPU Utilized: 00:49:55  
CPU Efficiency: 12.57% of 06:37:04 core-walltime  
Job Wall-clock time: 00:49:38  
Memory Utilized: 826.77 MB  
Memory Efficiency: 2.02% of 40.00 GB  

```{bash hisat_sh, eval=FALSE}
#!/bin/bash -l
#SBATCH --job-name=hisat2  # Optional job name
#SBATCH --ntasks=2      # Total number of tasks
#SBATCH --cpus-per-task=4
#SBATCH --mem=40g      # max memory limit
#SBATCH --time=1:00:00   # Walltime limit
#SBATCH --mail-type=begin
#SBATCH --mail-type=end
#SBATCH --mail-user=songs005@umn.edu
#SBATCH --array=1-39 # this will run one job for each sample

## This pulls from a tab-delimited file (array_config.txt) which has two columns. 
## First column is labeled ArrayTaskID, second is Sample as the header and first row
## array variable above indicates column 1 row labeled "10" which has a file ID prefix in column 2
## looks like:
## 10	Sample_ID

config=/scratch.global/songs005/aphal_rnaseq/reff/config.txt
sample=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $2}' $config)

# set dirs
genomedir="/scratch.global/songs005/aphal_rnaseq/reff"
fastqdir="/scratch.global/songs005/aphal_rnaseq/trimmed_data"
outdir="/scratch.global/songs005/aphal_rnaseq/hisat2_output_msdins_array" # with hisat2 output

# make a specific dir for this job
mkdir -p $outdir
mkdir -p $outdir/$sample

# load modules
module load hisat2
module load samtools

# build index
# hisat2-build $genomedir/10511_Aphal_PT_AllpathsLG_LINKS_jelly_pilon.fna $genomedir/aphal_hisat_index

# run hisat2
hisat2 -x $genomedir/aphal_hisat_index \
-1 $fastqdir/${sample}_trim_R1.fastq.gz \
-2 $fastqdir/${sample}_trim_R2.fastq.gz \
-S $outdir/$sample/${sample}.sam \
--phred33 \
--rna-strandness FR \
--dta \
--max-intronlen 3000 \
-t # print walltime

# convert sam to bam format
samtools view -uS $outdir/$sample/${sample}.sam | samtools sort -o $outdir/$sample/${sample}.bam
samtools index $outdir/$sample/${sample}.bam

```

### Featurecounts

#### Subread installation

Next we run featurecounts from the subread package. To use featurecounts, I must install the subead package on MSI. 

```{bash install_subread, eval=FALSE}
# exit qc environment
$ conda deactivate

# make new environment
$ conda create --name subread_env
$ conda activate subread_env

# install subread
$ conda install bioconda::subread
$ conda list
# packages in environment at /users/2/songs005/.conda/envs/subread_env:
#
# Name                    Version                   Build  Channel
_libgcc_mutex             0.1                        main
_openmp_mutex             5.1                       1_gnu
libgcc-ng                 11.2.0               h1234567_1
libgomp                   11.2.0               h1234567_1
subread                   2.0.1                h5bf99c6_1    bioconda
zlib                      1.2.13               h5eee18b_1


```


#### featurecounts_v1.sh

This script will only run after running the following on the console:

```{bash activate_env, eval=FALSE}
module load conda
conda activate subread_env
```

bash script below:

```{bash featurecounts.sh, eval=FALSE}
#!/bin/bash -l
#SBATCH --job-name=featurecounts  # Optional job name
#SBATCH --ntasks=1      # Total number of tasks
#SBATCH --cpus-per-task=8
#SBATCH --mem=64g      # max memory limit
#SBATCH --time=2:00:00   # Walltime limit
#SBATCH --mail-type=begin
#SBATCH --mail-type=end
#SBATCH --mail-user=songs005@umn.edu
#SBATCH --array=1-39

config=/scratch.global/songs005/aphal_rnaseq/reff/config.txt
sample=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $2}' $config)


# set dirs
genomedir="/scratch.global/songs005/aphal_rnaseq/reff"
fastqdir="/scratch.global/songs005/aphal_rnaseq/trimmed_data"
outdir="/scratch.global/songs005/aphal_rnaseq/hisat2_output_msdins_array" # with star output
countdir="/scratch.global/songs005/aphal_rnaseq/hisat2_featurecounts_output_msdins" # for featureCounts output

# mkdir
mkdir -p $countdir
mkdir -p $countdir/$sample

featureCounts -T 20 \
		-a $genomedir/aphal_reff_with_msdins.gff3 \
		-o $countdir/$sample/${sample}_featurecounts.txt \
		--minOverlap 20 \
		-g Parent \
		-B \
		-C \
		-p \
		$outdir/$sample/${sample}.bam

# arguments for featureCounts
# -a genome annotation file
# -o output filename
# -g parses the attribute 'Parent' in the gff3 file
# -b include only fragments with both ends successfully aligned
# -C do not count chimeric fragments where two ends align to diff chr
# -p specify paired-end reads
# input file is listed last with no flag


```

### Investigating mapping

Mapping rates with this pipeline ranged from 4.3% in one sample (!) to 67.4%, with a mean of 47.4%. This could be from environmental contamination, or something in my code. To investigate, I blasted some of the unmapped reads using decontaminer

https://github.com/amarinderthind/decontaminer/blob/master/

```{bash eval=FALSE}
# download decontaMiner
# https://github.com/amarinderthind/decontaminer/blob/master/decontaMiner_1.4.tar.gz
# transfer using filezilla

# decompress
tar -xvzf decontaMiner_1.4.tar.gz

# I need to make sure the following modules are loaded & added to the configuration file for decontaminer

# I followed the directions in the userguide: https://github.com/amarinderthind/decontaminer/blob/master/InstallationAndUserGuide_v1.2.pdf

# download all the bacteria, virus, and fungi refseq files from NCBI
# it took 23 minutes to download all the bacteria seqs
# fungi and viral ran much faster, 1-5 mins each
lftp https://ftp.ncbi.nlm.nih.gov/refseq/release/bacteria/ -e "mirror --parallel=5 --include-glob *.fna.gz .; bye"
lftp https://ftp.ncbi.nlm.nih.gov/refseq/release/fungi/ -e "mirror --parallel=5 --include-glob *.fna.gz .; bye"
lftp https://ftp.ncbi.nlm.nih.gov/refseq/release/viral/ -e "mirror --parallel=5 --include-glob *.fna.gz .; bye"

# start interactive job
srun -N 1 --ntasks-per-node=16 --mem=60gb --gres=gpu:a40:1 -t 2:00:00 -p interactive-gpu --tmp 100gb --pty bash

# concatenate into one file
cat fungi* > fungi_all.fna

# bacteria took about 3 hr to concatenate
cat bacteria* > bacteria_all.fna
cat viral* > viral_all.fna

# make dbs

module load ncbi_blast
which blastn

$ makeblastdb -version
makeblastdb: 2.13.0+
 Package: blast 2.13.0, build Mar 17 2023 11:11:04

makeblastdb -in viral_all.fna -out Viruses -dbtype nucl -title "Viruses" -parse_seqids -max_file_sz 20GB

# took an hour or so
makeblastdb -in fungi_all.fna -out Fungi -dbtype nucl -title "Fungi" -parse_seqids -max_file_sz 20GB


# this one took about 5 hr to run in a .sh job
makeblastdb -in bacteria_all.fna -out Bacteria -dbtype nucl -title "Bacteria" -parse_seqids -max_file_sz 20GB

```

Next we need to set up the configuration file
```{bash eval = FALSE}
# blastn
/common/software/install/migrated/ncbi-blast/2.13.0/c++/bin/blastn

module load samtools
which samtools

/common/software/install/spack/linux-centos7-ivybridge/gcc-8.2.0/samtools-1.16.1-egljrr3x7n4n4jvct2rhopk24ndtt3tb/bin/samtools


module load fastx_toolkit
which fastq_quality_filter

/common/software/install/migrated/fastx_toolkit/0.0.14/bin/fastq_quality_filter

```

### Fastqc on unmapped reads

```{bash eval=FALSE}
#!/bin/bash -l
#SBATCH --job-name=1unmapped_fastqc  # Optional job name
#SBATCH --ntasks=1      # Total number of tasks
#SBATCH --cpus-per-task=8
#SBATCH --mem=64g      # max memory limit
#SBATCH --time=2:00:00   # Walltime limit
#SBATCH --mail-type=begin
#SBATCH --mail-type=end
#SBATCH --mail-user=songs005@umn.edu
#SBATCH --array=1-39
config=/scratch.global/songs005/aphal_rnaseq/reff/unmapped_aphal_config.txt
sample=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $2}' $config)

# source activate qc

# location of unmapped reads

data=/scratch.global/songs005/aphal_rnaseq/hisat2_output_msdins_array_unmapp

# output dir
dir=/scratch.global/songs005/aphal_rnaseq/unmapped_fastqc

# make output directory
mkdir -p $dir

# then run QC on the raw reads
fastqc -o $dir/${sample} $data/*.1.fastq
# fastqc -o $dir/${sample} $data/*.2.fastq


```


```{r extract_overrep_seqs}
unmapp_path = "C:/Users/livia/Documents/02-drott-lab-files/leaderless_Aphalloides/unmapped_fastqc"

list_unmapped <- list.files(path=unmapp_path,recursive=TRUE,pattern="fastqc_data.txt",full.names=TRUE)

read_fastqc <- function(filename) {
  #filename=list_unmapped[1]
  filename_simp <- strsplit(filename, "/")[[1]][9]
  temp <- readLines(filename)
  
  # find row with overrepresented seqs
  
  temp <- as.data.frame(Map(function(i,j) read.table(text=temp[(i+1):(j-2)], sep='', header=FALSE), grep('>>Overrepresented', temp), grep('>>Adapter', temp)))
  
  # rename columns
  colnames(temp) <- c("Sequence","Count","Percentage","Possible_source")
  temp$header <- paste0(">",rownames(temp))
  
  # extract seqs as a fasta
  sequence_list <- as.vector(rbind(temp$header, temp$Sequence))
  
  # save temp as output in a folder
  outdir = "C:/Users/livia/Documents/02-drott-lab-files/leaderless_Aphalloides/unmapped_fastqc/overrep_stats/"

  outdir2 = "C:/Users/livia/Documents/02-drott-lab-files/leaderless_Aphalloides/unmapped_fastqc/overrep_seqs/"
  
  write.csv(temp, paste0(outdir,filename_simp,"_fastqc_overrep_stats.csv"),row.names=FALSE)
  write.table(sequence_list, 
            file = paste0(outdir2, filename_simp, "_fastqc_overrep_seqs.fasta"), 
            row.names = FALSE, 
            col.names = FALSE, 
            quote = FALSE)
  
}

# apply function to all entries on list
lapply(list_unmapped, read_fastqc)


```

align reads to 18s rRNA
```{bash eval=FALSE}
module load bwa
cd /scratch.global/songs005/aphal_rnaseq/its18s

bwa index its18s.fna

bwa mem -t 10 its18s.fna ../hisat2_output_msdins_array_unmapp/10708_S250_L002/10708_S250_L002_unmapped.1.fastq ../hisat2_output_msdins_array_unmapp/10708_S250_L002/10708_S250_L002_unmapped.2.fastq
#Real time: 244.883 sec; CPU: 2140.206 sec

module load picard

java -jar /common/software/install/migrated/picard/2.25.6/picard.jar SortSam I=mAF.sam O=alignment.sorted.bam SORT_ORDER=coordinate
# Elapsed time: 10.92 minutes.

java -jar /common/software/install/migrated/picard/2.25.6/picard.jar BuildBamIndex INPUT=alignment.sorted.bam

#Elapsed time: 1.01 minutes.


rm mAF.sam

```



### DESeq2

#### extract mapping efficiency for hisat2

```{r prepare_dirs_libraries}
# import data and load packages
suppressMessages(library(DESeq2))
suppressMessages(library(rmarkdown))
library(dplyr)
library(tidyr)
library(readr)

dir <- setwd("C:/Users/livia/Documents/02-drott-lab-files/leaderless_Aphalloides")
dir
# make output directories
subDir <- paste0(dir,"/Output_",Sys.Date())
dir.create(path=subDir, showWarnings = FALSE)
dir.create(paste0(subDir,"/Volcano_plots"), showWarnings = FALSE)
dir.create(paste0(subDir,"/NormCount-Graphs"), showWarnings = FALSE)
dir.create(paste0(subDir,"/NormCount-Graphs/Data"), showWarnings = FALSE)

```

```{r hisat_mapping_eff}
# path to dir containing slurm-x.out files
# slurm_out_path <- "D:/Aphalloides_rnaseq_for_leaderless/hisat2_output_msdins_array/"
slurm_out_path <- "C:/Users/livia/Documents/02-drott-lab-files/leaderless_Aphalloides/hisat_output"
# get list of file names
out_files <- list.files(path=slurm_out_path, pattern=".out",full.names=TRUE,recursive=TRUE) 

# write a function to extract mapping efficiency

extract_hisat_mapping <- function(file_name) {
  # for debugging:
  #file_name = out_files[2]
  
  # open filename
  library(readr)
  temp <- read_tsv(file_name,show_col_types = FALSE)
  
  # Find the row index that contains "overall alignment rate"
  # this is typically third from the bottom
  index = nrow(temp)-2
  #temp2<-temp[grepl("overall alignment rate",temp[,1]),]
  mapping <- unlist(temp[index,1])
  
  
  
  # if this string contains %, then split by %, else print error
 if (grep("%", mapping)==TRUE) {
   
   # extract percent
   perc <- unlist(strsplit(mapping,split="%"))[1]
   
   # return this value to the console
   return(perc)
   
 } else print("Error: mapping rate not found")
  
}

# test it
extract_hisat_mapping(out_files[3])

# it works! now sapply to extract all the values

# mapping <- data.frame(Input = out_files, perc_mapping = sapply(out_files, extract_hisat_mapping))

# that didn't work because one or more files is not correctly formatted... use a loop
mapping <- data.frame(Array = list.files(path=slurm_out_path, pattern=".out",full.names=FALSE,recursive=TRUE) , perc_mapping = "")

# for (i in 1:length(out_files)) {
for (i in c(1:length(out_files))) {
  mapping[i,2] <- as.numeric(extract_hisat_mapping(out_files[i]))
} 

# find array index number for each sample
mapping$Array <- gsub("\\.out", "", mapping$Array)

# keep only second half of the Array name
mapping$Array <- sub(".*_", "", mapping$Array)

# Convert Array column to numeric and reorder
mapping <- mapping %>%
  mutate(Array = as.numeric(Array)) %>%
  arrange(Array)

# now match this to the metadata file
metadata <- readxl::read_xlsx("C:/Users/livia/Documents/02-drott-lab-files/leaderless_Aphalloides/metadata.xlsx",sheet="metadata")
metadata$perc_mapping <- as.numeric(mapping$perc_mapping)
metadata[,c("Sample_ID","Population","Origin","perc_mapping")]

# find min, max, avg mapping rate
min(metadata$perc_mapping)
max(metadata$perc_mapping)
mean(metadata$perc_mapping)

# print mapping
rmarkdown::paged_table(as.data.frame(metadata[,c("Sample_ID","Population","Origin","tot_reads_mill_trim","perc_mapping")]))

# save as csv
write.csv(metadata,paste0(subDir,"/metadata_plus_mapping.csv"),row.names=FALSE)
```


#### Edit gff to add MSDINs

I added the leadered and leaderless MSDINs / RiPPs to the gff as below. Note that the UTRs, introns are not properly annotated in my modified gff.

```{r add_msdins_gff}
# disable scientific notation in R
# this is important because otherwise some chr locations will export in sci notation
# which can break packages like e.g. featurecounts
options(scipen = 999)

# Read the GFF file (GFF files are tab-delimited)
gff_data <- read_tsv("C:/Users/livia/Documents/02-drott-lab-files/aphalloides_reff/reff/t_5cc30df297ef2-5e76fa469d2f4-pasa_refine.gensas.gff3/t_5cc30df297ef2-5e76fa469d2f4-pasa_refine.gensas.gff3", comment = "#", col_names = FALSE,show_col_types = FALSE)

# read in new msdin list from Mickey
msdins <- read_tsv("C:/Users/livia/Documents/02-drott-lab-files/aphalloides_reff/reff/cds_for_liv.bed", comment = "#", col_names = FALSE,show_col_types = FALSE)

# read in key for renaming chromosomes
key <- read_tsv("C:/Users/livia/Documents/02-drott-lab-files/aphalloides_reff/reff/10511_Aphal_PT_AllpathsLG.LINKS.jelly.pilon_chrm_name_key", comment = "#", col_names = FALSE,show_col_types = FALSE)

# Remove '>' from all elements in the key dataframe
key[] <- lapply(key, function(x) gsub(">", "", x))
colnames(key) <- c("new_name","old_name")
# rename the chromosomes in the msdins dataframe
msdins <- msdins %>%
  left_join(key, by = c("X1" = "old_name")) %>%
  mutate(X1 = ifelse(is.na(new_name), X1, new_name)) %>%
  dplyr::select(-new_name)


# Add a unique number to duplicate values in column V4
msdins$X4 <- make.unique(msdins$X4, sep = "_")

# find exon and intron info from original .bed files
leaderless <- read_tsv("C:/Users/livia/Documents/02-drott-lab-files/aphalloides_reff/reff/leaderless/processed_best_msdin_final.bed", col_names = FALSE,show_col_types = FALSE)

leadered <- read_tsv("C:/Users/livia/Documents/02-drott-lab-files/aphalloides_reff/reff/leadered/processed_best_msdin_final.bed", col_names = FALSE,show_col_types = FALSE)

# rename chr for these
leaderless <- leaderless %>%
  left_join(key, by = c("X1" = "old_name")) %>%
  mutate(X1 = ifelse(is.na(new_name), X1, new_name)) %>%
  dplyr::select(-new_name)

leadered <- leadered %>%
  left_join(key, by = c("X1" = "old_name")) %>%
  mutate(X1 = ifelse(is.na(new_name), X1, new_name)) %>%
  dplyr::select(-new_name)


# identify which are which
find_msdin_name <- function(query,chr) {
  # for a given query sequence, check which chromosome
  #query = leadered$X2[4]
  #chr = leadered$X1[4]
  # then find the pair of values it is between
  query = as.numeric(query)
  temp <- msdins[msdins$X1==chr,]
  
  # if temp is not length 0, proceed, else end
  if (nrow(temp) > 0 ) {
    # make sure everything is numeric
    temp$X2 <- as.numeric(temp$X2)
    temp$X3 <- as.numeric(temp$X3)
  
    # output the name of the MSDIN
    result <- temp %>%
    filter(query >= X2 & query <= X3) %>%
    pull(X4)
  
    return(result)
  } else {
    return("NA")
  }
  
}

# get msdin names
leaderless$name <- mapply(find_msdin_name, leaderless$X2, leaderless$X1)
leadered$name <- mapply(find_msdin_name, leadered$X2, leadered$X1)

# extract info from column X4 which has attribute type and whole gene positions
# want to keep values 1 and 12
leadered[,c("attr","pos")] <- data.frame(do.call("rbind", strsplit(as.character(leadered$X4), "_",
                                     fixed = TRUE)))[,c(1,12)]

leaderless[,c("attr","pos")] <- data.frame(do.call("rbind", strsplit(as.character(leaderless$X4), "_",
                                     fixed = TRUE)))[,c(1,12)]

# extract de-duplicated gene position info
gene_data <- data.frame(do.call("rbind", strsplit(as.character(leaderless$pos), ":",
                                     fixed = TRUE)))
gene_data[,2:3] <- data.frame(do.call("rbind", strsplit(as.character(gene_data$X2), "(",
                                     fixed = TRUE)))
# remove other )
gene_data[] <- lapply(gene_data, function(x) gsub(")", "", x))

gene_data[,4:5] <- data.frame(do.call("rbind", strsplit(as.character(gene_data$X2), "-",
                                     fixed = TRUE)))

# add names and remove dups
gene_data$name <- leaderless$name
gene_data$chr <- leaderless$X1
gene_data <- gene_data[,c("name","chr","X1.1","X2.2","X2.1")]
gene_data <- unique(gene_data)

# repeat for leadered
gene_data2 <- data.frame(do.call("rbind", strsplit(as.character(leadered$pos), ":",
                                     fixed = TRUE)))
gene_data2[,2:3] <- data.frame(do.call("rbind", strsplit(as.character(gene_data2$X2), "(",
                                     fixed = TRUE)))
# remove other )
gene_data2[] <- lapply(gene_data2, function(x) gsub(")", "", x))

gene_data2[,4:5] <- data.frame(do.call("rbind", strsplit(as.character(gene_data2$X2), "-",
                                     fixed = TRUE)))

# add names and remove dups
gene_data2$name <- leadered$name
gene_data2$chr <- leadered$X1
gene_data2 <- gene_data2[,c("name","chr","X1.1","X2.2","X2.1")]
gene_data2 <- unique(gene_data2)

# merge together
gene_data_all <- rbind(gene_data,gene_data2) 

# remove samples where name is not in msdins
gene_data_all <- subset(gene_data_all, name %in% msdins$X4)

# Ensure both data frames are sorted based on the "name" column
gene_data_all$name <- as.character(gene_data_all$name)
gene_data_all <- gene_data_all[order(gene_data_all$name), ]
msdins <- msdins[order(msdins$X4), ]

# example of old bed file
# Contig0	19703	19843	MYNPPYFLPP	N/A	-	3	MYNPPYFLPPCVSDDIEMVLTRGESLC*

# example of GFF file
# Contig0	5e757d1f96d78-evm	CDS	11712	11935	.	+	0	ID=26557-Ap.00g000010.m01.CDS01;Name=26557-Ap.00g000010.m01.CDS01;Parent=26557-Ap.00g000010.m01;original_ID=cds.Ap.00g000010.m01;Alias=cds.Ap.00g000010.m01;

# types of attributes
unique(gff_data$X3)

# so I need to generate a unique file for each of these with the correct chr positions
# there are sometimes multiple exons
attr_all <- rbind(leaderless,leadered)

# only keep ripps present in list from Mickey
attr_all <- subset(attr_all, name %in% msdins$X4)


# sort
attr_all$name <- as.character(attr_all$name)
attr_all <- attr_all[order(attr_all$name), ]

# see types
unique(attr_all$attr)

# subset to exon
attr_all1 <- subset(attr_all, attr == "exon1")
attr_all2 <- subset(attr_all, attr == "exon2")

# extract columns in the correct order to append to the gff
msdins_cds <- as.data.frame(attr_all1$X1) # chromosome
msdins_cds[,2] <- "5e757d1f96d78-evm" # I think this is genome?
msdins_cds[,3] <- "CDS" # attribute type
msdins_cds[,4] <- attr_all1$X2 # start pos
msdins_cds[,5] <- attr_all1$X3 # end pos
msdins_cds[,6] <- "." # score; . means NA
msdins_cds[,7] <- attr_all1$X6 # + or - strand direction
msdins_cds[,8] <- 0 # phase
# The reading frame phase for CDS features (0, 1, 2; . for non-CDS)
# if it is on the - strand, paste a 2
msdins_cds <- msdins_cds %>%
  mutate(V8 = ifelse(V7 == "-", 2, 0))
# attributes column
msdins_cds[,"X9"] <- paste0("ID=", msdins$X4,".m01.CDS01;Name=", msdins$X4,".m01.CDS01;Parent=", msdins$X4,".m01;original_ID=cds.", msdins$X4,".m01;Alias=cds.", msdins$X4,".m01;") 

# duplicate for second exon & adjust start and end pos
msdins_cds2 <- msdins_cds
msdins_cds2[,4] <- attr_all2$X2 # start pos
msdins_cds2[,5] <- attr_all2$X3 # end pos
msdins_cds2[,"X9"] <- paste0("ID=", msdins$X4,".m01.CDS02;Name=", msdins$X4,".m01.CDS02;Parent=", msdins$X4,".m01;original_ID=cds.", msdins$X4,".m01;Alias=cds.", msdins$X4,".m01;") 

# repeat and label as exons
msdins_exon <- msdins_cds
msdins_exon[,3] <- "exon"
msdins_exon[,8] <- "."
msdins_exon[,9] <- paste0("ID=", msdins$X4,".m01.exon01;Name=", msdins$X4,".m01.exon01;Parent=", msdins$X4,";original_ID=", msdins$X4,".m01.exon1;Alias=", msdins$X4,".m01.exon1;") 

# duplicate for second exon
msdins_exon2 <- msdins_cds2
msdins_exon2[,3] <- "exon"
msdins_exon2[,8] <- "."
msdins_exon2[,9] <- paste0("ID=", msdins$X4,".m01.exon02;Name=", msdins$X4,".m01.exon02;Parent=", msdins$X4,";original_ID=", msdins$X4,".m01.exon2;Alias=", msdins$X4,".m01.exon2;") 

# repeat and label as a gene
msdins_gene <- msdins_cds
msdins_gene[,3] <- "gene"
msdins_gene[,8] <- "."
msdins_gene[,4] <- gene_data_all$X1.1 # start pos
msdins_gene[,5] <- gene_data_all$X2.2 # end pos
msdins_gene[,9] <- paste0("ID=", msdins$X4,";Name=", msdins$X4,";original_ID=", msdins$X4,";Alias=", msdins$X4,";original_name=",msdins$X4,";") 

# repeat and label as mRNA
msdins_mRNA <- msdins_gene
msdins_mRNA[,3] <- "mRNA"
msdins_mRNA[,9] <- paste0("ID=", msdins$X4,".m01;Name=", msdins$X4,".m01;Parent=", msdins$X4,";original_ID=", msdins$X4,".m01;Alias=", msdins$X4,".m01;original_name=",msdins$X4,";") 


msdins_all <- rbind(msdins_cds,
                  msdins_exon,
                  msdins_cds2,
                  msdins_exon2,
                  msdins_gene,
                  msdins_mRNA)

# append to the end of gff_data
colnames(msdins_all) <- colnames(gff_data)

gff_data2 <- rbind(gff_data,msdins_all)

# sort gff_data2 by chromosome (column V1) and position (column V4)
# Convert the 'start' column to numeric (if not already)
gff_data2$X4 <- as.numeric(gff_data2$X4)

# Sort the dataframe by 'seqid' (chromosome/contig) and 'start' position
gff_sorted <- gff_data2[order(gff_data2$X1, gff_data2$X4), ]

colnames(gff_sorted) <- c("seqid", "source", "type", "start", "end", "score", "strand", "phase", "attributes")

# save sorted gff
write.table(gff_sorted, "aphal_reff_with_msdins.gff3", sep = "\t", quote = FALSE, row.names = FALSE, col.names = FALSE)

# remove vars
rm(gff_data,gff_data2)
rm(msdins_cds,msdins_exon,msdins_gene,msdins_mRNA,msdins_cds2,msdins_exon2)
rm(attr_all1,attr_all2,gene_data,gene_data2)
```

#### Import & initial analysis

```{r read_data}
# set factor level; this is important for comparisons later
# group levels that are listed earlier in the list
# will be prioritized as the denominator when you do DESEq2 comparisons
# IE - the "wild type" or "control"
metadata$Origin <- factor(metadata$Origin, levels = c("EU", "CA"))


# paged_table(metadata)

# make sure all files are present
all(file.exists(metadata$Count_file))

# if necessary - subset to only include samples where the file exists
metadata <- metadata[file.exists(metadata$Count_file),]
metadata[,c("Sample_ID","Population","Origin","perc_mapping")]

# find min, max, avg mapping rate
min(metadata$perc_mapping)
max(metadata$perc_mapping)
mean(metadata$perc_mapping)

all(file.exists(metadata$Count_file))

# exclude pet5 (low mapping rate, 4%) and pet1-redo
metadata <- metadata[!metadata$Sample_ID %in% c("Pet1-redo","Pet5"),]
# import data - first get file names
files <- metadata$Count_file

# associate those with sample ID
names(files) <- paste(metadata$Sample_ID)

# import the featurecounts files
import_counts <- function(file_name) {
  # first line is for debugging
  # file_name = files[1]
  # extract sample prefix
  File_prefix <- unlist(strsplit(file_name,"/"))[8]
  
  temp <- read_tsv(file_name,comment="#",show_col_types = FALSE)
  # rename column to File_prefix
  colnames(temp)[7] <- File_prefix
  # output the column of counts
  output <- as.data.frame(temp[,7])
  rownames(output) <- temp$Geneid
  return(output)
}

# now run import_counts and cbind results together for all filenames in files
output_list <- lapply(files, import_counts)

# bind them together
cts <- as.matrix(do.call(cbind, output_list))

head(cts,2)

# check that the row order of metadata and column order of cts match

coldata <- as.data.frame(metadata[,c("Origin","Population")])
rownames(coldata) <- metadata$File_prefix

coldata$Origin <- factor(coldata$Origin)
coldata$Population <- factor(coldata$Population)

coldata

all(rownames(coldata) %in% colnames(cts))
all(rownames(coldata) == colnames(cts))

# both of these are true!
# in case one of these was false, use the following logic:
cts <- cts[, rownames(coldata)]
all(rownames(coldata) == colnames(cts))

# finally - generate dds object
dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design = ~ Origin)
dds

# remove low-count genes that have a mean count below 5
# keep <- rowSums(counts(dds)) >= 10
keep <- rowMeans(counts(dds)) >= 5

sum(keep)

length(dds)
# find percentage of genes that have been kept after applying filter for low counts
sum(keep) / length(dds) * 100

# now subset your dds object to keep only "keep" rows
dds <- dds[keep,]

```

```{r run_deseq}
dds <- DESeq(dds)
res = results(dds, alpha=0.05, independentFiltering=FALSE, cooksCutoff=TRUE)
summary(res)
resultsNames(dds)
```


### Generate RNAseq plots

#### Volcano plots

```{r volcano_function}
# summarize results from dds
# group1 will be the numerator (ie, treatment)
# group2 will be denominator (ie, control)
# gene_list is the list of genes you want to annotate on the volcano plot

make_volcano <- function(group1,group2,gene_list = msdins$X4) {
  # group1 = "CA"
  # group2 = "EU"
  # gene_list = msdins$X4
  print(paste0(group1," vs ",group2))
  
  res <- results(dds, contrast=c("Origin", group1, group2), alpha=0.05, independentFiltering=FALSE, cooksCutoff=TRUE)
  
  # now save deseq results as a dataframe
  deseqoutput <- as.data.frame(res)
  
  # plot it
  library(EnhancedVolcano)
  EnhancedVolcano(deseqoutput,
                  lab = rownames(res),
                  selectLab = gene_list,
                  title = paste0(group1," vs. ",group2),
                  subtitle = bquote(
                    italic("")),
                  caption = "",
                  x = 'log2FoldChange',
                  y = 'padj',
                  pCutoff = 0.05,
                  FCcutoff = 1,
                  ylab = bquote(~-Log[10] ~ italic("Adj. P value")),
                  legendPosition = 'bottom',
                  typeConnectors ="closed",
                  drawConnectors = TRUE,
                  widthConnectors = 1,
                  arrowheads = FALSE,
                  labSize = 4,
                  max.overlaps = 15,
                  lengthConnectors = unit(0.02, "npc")) +
    ggplot2::coord_cartesian(xlim=c(-6, 6), ylim=c(0,30)) +
    ggplot2::scale_x_continuous(breaks=seq(-5,5, 1))
  
  ggsave(paste0(subDir,"/Volcano_plots/",group1,"_vs_",group2,"_volcano.png"),
         units ="in",
         width = 10,
         height = 10)
  
  summary(res)
  
  # # shrink log fold changes
  # resLFC <- lfcShrink(dds, coef=paste0("Group_",group2,"_vs_",group1), type="apeglm")
  # resLFC
  # 
  # # use MA plot to visualize log2 fold changes
  # plotMA(res,ylim=c(-2,2))
  # 
  # # plot the shrunken LFC which should remove noise from low count genes
  # plotMA(resLFC, ylim=c(-2,2))
}

```

```{r generate_volcanos, fig.width = 8, fig.asp = .8}
make_volcano(group2 = "EU",
             group1 = "CA")

```

#### Counts for single genes

``` {r make_count_plot_function}
# make a plot for every gene and save it in a folder...
make_count_plot <- function(geneID) {
  # geneID = paste0(msdins$X4[10],".m01")
  gene <- plotCounts(dds, gene = geneID, intgroup = "Origin", returnData = TRUE)

  # Define color palette for Origin
  gene$Origin <- factor(gene$Origin, levels = c("CA",
                                                    "EU"))
  
  # also add pop information
  gene$Population <- metadata$Population   

  gene$Population <- factor(gene$Population, levels = c("Drake",
                                                            "Pet",
                                                            "Picnic",
                                                            "Aso",
                                                            "Champ",
                                                            "Doc",
                                                            "Gron",
                                                            "Lamp",
                                                            "Quill",
                                                            "Tisza"))
                          
  # genotype_colors <- c("#717568","#3F4739", "#FF01FB", "#0CCA4A","grey40","grey60")
  # colors for origin:
  # genotype_colors <- c("#FE4A49", "#2292A4")

  genotype_colors <- c("#74121D","#af2930","#FE4A49",
                     "#03045e","#023e8a","#0077b6","#0096c7","#00b4d8","#48cae4","#90e0ef")

ggplot(data=gene,aes(x=Origin,y=count)) +
  geom_point(aes(colour = Population), size = 4, position = position_jitter(w = 0.3, h = 0)) +
  # add mean line
  stat_summary(fun= mean, fun.min=mean, fun.max=mean, geom="crossbar", width=0.5, linewidth=1,color="black") +
  # add error bars
  stat_summary(fun.data=mean_se, fun.args = list(mult=1), geom="errorbar", width=0.2, linewidth=1,color="black") +
  theme_classic()  +
  scale_color_manual(values = genotype_colors) +
  theme(legend.position = "none",
        text = element_text(size = 16),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 14)) +
  ylab("Normalized count") +
  ggtitle(paste0(geneID))

  # save graph
  ggsave(paste0(geneID,"_normalized_counts.png"),
         device="png",dpi="print",
         units = "in", width = 5, height = 3,
         path=paste0(subDir,"/NormCount-Graphs"))
  # save data table 
  write.csv(gene,paste0(subDir,"/NormCount-Graphs/Data/",geneID,".csv"))
}

```

```{r generate_norm_count_plots}
# MSDINs, leadered and leaderless:
list <- msdins$X4

# first see which of these genes have any counts at all
# get counts matrix for all genes
counts <- counts(dds, normalized=TRUE)
# find list of RiPPs also in count matrix
list <- intersect(list, rownames(counts))

# loop through gene list
for(i in 1:length(list)) {
  genename = list[i]
  make_count_plot(geneID=genename) # takes ~1.5 hr to run on 9000 genes
}

# in the future we could also plot a handful of housekeeping genes

# next: generate facet_wrap graph for all MSDINS

# also: violin plot for vsd expression of all


```


#### Variance stabilizing transformations
More info can be found at [DESeq2 Bioconductor tutorial](http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#exploring-and-exporting-results):

These figures plot the standard deviation of transformed data. A flat curve of the square root of variance over the mean is ideal.
```{r variance_stabilization, fig.show='hide'}
# Extracting transformed values
vsd <- vst(dds, blind=FALSE)
ntd <- normTransform(dds)

# extract the matrix of normalized values.
head(assay(vsd), 3)

# plots
library(vsn)
msd_dds <- meanSdPlot(assay(dds))
msd_vsd <- meanSdPlot(assay(vsd))
```

```{r variance_plots, fig.show="hold", out.width="50%"}
msd_dds$gg + ggtitle("Untransformed data") + ylim(-1,100)
msd_vsd$gg + ggtitle("Variance stabilized transformation")

```


#### Supervised clustering
Check the heatmap of a subset of the data to see if replicates look similar to each other. This type of heatmap cluster is supervised, since we are picking the 20 genes with the biggest changes.

It looks like 3 of the RiPPs are included in this list of top 20 genes with biggest changes, including the putative leaderless!

```{r supervised_clustering}

# find 15 genes with highest expression levels from dds
select <- order(rowMeans(counts(dds,normalized=TRUE)),
                decreasing=TRUE)[1:15]

# make new data frame with only Population stage info
df <- as.data.frame(colData(dds)[,c("Population")])
colnames(df) <- c("Population")
#samples <- colnames(assay(ntd))
samples <- metadata$Sample_ID
rownames(df) <- samples

# heatmap of variance stabilized data
library(pheatmap)

# extract data
mat <- assay(vsd)[select,]
top20 <- row.names(mat)
colnames(mat) <- metadata$Sample_ID

# remove the random prefix and suffixes
row.names(mat) <- gsub("^[^-]+-|\\.m01$", "", row.names(mat))
row.names(mat)

pheatmap(mat, cluster_rows=FALSE, 
         show_rownames=TRUE,
         cluster_cols=TRUE, annotation_col=df)

# also make heatmap of genes with custom colors
genotype_colors <- c("#74121D","#af2930","#FE4A49",
                     "#03045e","#023e8a","#0077b6","#0096c7","#00b4d8","#48cae4","#90e0ef")

annotation_colors <- list(Population = setNames(genotype_colors, unique(df$Population)))

# Define your custom color scale (from dark blue to aqua)
my_colors <- colorRampPalette(c("grey90","#03045e"))(100)


pheatmap(mat, cluster_rows=FALSE, 
         show_rownames=TRUE,
         cluster_cols=TRUE,
         annotation_col=df,
         annotation_colors = annotation_colors,
         legend=TRUE,
         color=my_colors,
         border_color = "transparent",
         fontsize_row = 10,  # Row label font size
         fontsize_col = 10)

```

#### PCA / unsupervised clustering 

A great interactive explanation of PCA plots is [here](https://bioboot.github.io/bggn213_F20/class-material/pca/)

```{r cluster_heatmap_and_pca}
# find distances between samples
sampleDists <- dist(t(assay(vsd)))

# reformat distances
sampleDistMatrix <- as.matrix(sampleDists)

# make row and column names the same as sample IDs
rownames(sampleDistMatrix) <- rownames(df)
colnames(sampleDistMatrix) <- rownames(df)

# generate some nice colors
library(RColorBrewer)
colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255)

# plot it
pheatmap(sampleDistMatrix,
         clustering_distance_rows=sampleDists,
         clustering_distance_cols=sampleDists,
         col=colors)

# next lets generate a PCA plot on variance stabilized data
vsd_out <- assay(vsd)

# run PCA analysis
pca <- prcomp(t(vsd_out))

# plot scree
library(factoextra)
fviz_eig(pca)

# Create data frame with metadata and PC3 and PC4 values for input to ggplot
pcaData <- cbind(metadata[,c(2:5,8,13)], pca$x)

# Define color palette for genotypes
pcaData$Origin <- factor(pcaData$Origin, levels = c("CA",
                                                    "EU"))

genotype_colors <- c("#FE4A49", "#2292A4")

# find percent variance for PC1 and PC2
# summary of variance
pcasummary <- summary(pca)
pcasummary
pc1var <- round(pcasummary$importance[2],digits = 4) * 100
pc2var <- round(pcasummary$importance[5],digits = 4) * 100
pc3var <- round(pcasummary$importance[8],digits = 4) * 100
pc4var <- round(pcasummary$importance[11],digits = 4) * 100


# plot PC1 and 2
ggplot(pcaData,aes(x=PC1, y=PC2, color = Origin, shape = Origin)) +
  geom_point(size=3) + 
  theme_classic() +
  scale_color_manual(values = genotype_colors) +
  xlab(paste0("PC1 (",pc1var,"% variance)")) +
  ylab(paste0("PC2 (",pc2var,"% variance)"))

ggsave("PCA_plot_pc12_origin.png",
       path = subDir,
       units="in",
       width = 6, height = 5)

# plot PC3 and 4
ggplot(pcaData,aes(x=PC3, y=PC4, color = Origin, size = Origin)) +
  geom_point(size=3) + 
  theme_classic() +
  scale_color_manual(values = genotype_colors) +
  xlab(paste0("PC3 (",pc3var,"% variance)")) +
  ylab(paste0("PC4 (",pc4var,"% variance)"))

ggsave("PCA_plot_pc34_origin.png",
       path = subDir,
       units="in",
       width = 6, height = 5)

# also plot where colors indicate population & shape indicates Origin

# deduplicate
t <- unique(metadata[,c(4,8)])
t

pcaData$Population <- factor(pcaData$Population, levels = c("Drake",
                                                            "Pet",
                                                            "Picnic",
                                                            "Aso",
                                                            "Champ",
                                                            "Doc",
                                                            "Gron",
                                                            "Lamp",
                                                            "Quill",
                                                            "Tisza"))
# first 3 are CA, last 7 are EU
genotype_colors <- c("#74121D","#af2930","#FE4A49",
                     "#03045e","#023e8a","#0077b6","#0096c7","#00b4d8","#48cae4","#90e0ef")


ggplot(pcaData,aes(x=PC1, y=PC2, color = Population, shape = Origin)) +
  geom_point(size=4) + 
  theme_classic() +
  scale_color_manual(values = genotype_colors) +
stat_ellipse(aes(group = Origin), colour = "black")+                 
  xlab(paste0("PC1 (",pc1var,"% variance)")) +
  ylab(paste0("PC2 (",pc2var,"% variance)"))

ggsave("PCA_plot_pc12_population_origin.png",
       path = subDir,
       units="in",
       width = 6, height = 5)

ggplot(pcaData,aes(x=PC3, y=PC4, color = Population, shape = Origin)) +
  geom_point(size=3) + 
  theme_classic() +
  scale_color_manual(values = genotype_colors) +
  xlab(paste0("PC3 (",pc3var,"% variance)")) +
  ylab(paste0("PC4 (",pc4var,"% variance)"))

ggsave("PCA_plot_pc34_population_origin.png",
       path = subDir,
       units="in",
       width = 6, height = 5)

## now plot PCA where color indicates mapping rate
ggplot(pcaData,aes(x=PC1, y=PC2, color = perc_mapping, shape = Origin)) +
  geom_point(size=3) + 
  theme_classic() +
  scale_color_viridis_c() +
  #paletteer::scale_color_paletteer_c("viridis::plasma") +
  #scale_color_manual(values = genotype_colors) +
  xlab(paste0("PC1 (",pc1var,"% variance)")) +
  ylab(paste0("PC2 (",pc2var,"% variance)"))

ggsave("PCA_plot_pc12_percmapping_origin.png",
       path = subDir,
       units="in",
       width = 6, height = 5)

# plot mapping rates for both pops
ggplot(pcaData, aes(x=Origin,y=perc_mapping, color=Population,shape=Origin)) +
  geom_point(size = 4, position = position_jitter(w = 0.3, h = 0)) +
  # add mean line
  stat_summary(fun= mean, fun.min=mean, fun.max=mean, geom="crossbar", width=0.5, linewidth=1,color="black") +
  # add error bars
  stat_summary(fun.data=mean_se, fun.args = list(mult=1), geom="errorbar", width=0.2, linewidth=1,color="black") + 
  scale_color_manual(values = genotype_colors) +
  theme_classic()


ggsave("percmapping_origin_population.png",
       path = subDir,
       units="in",
       width = 4, height = 5)

# export pca data for separate graphing
write.csv(pcaData[,1:10],paste0(subDir,"/pca_data.csv"),row.names=FALSE)


# also plot norm counts for leaderless with population colored...
gene <- plotCounts(dds, gene = "MLGFLVLP", intgroup = "Origin", returnData = TRUE)

  # Define color palette for Origin
  gene$Origin <- factor(gene$Origin, levels = c("CA",
                                                    "EU"))
  gene$Population <- metadata$Population   

  gene$Population <- factor(gene$Population, levels = c("Drake",
                                                            "Pet",
                                                            "Picnic",
                                                            "Aso",
                                                            "Champ",
                                                            "Doc",
                                                            "Gron",
                                                            "Lamp",
                                                            "Quill",
                                                            "Tisza"))
ggplot(data=gene,aes(x=Origin,y=count)) +
  geom_point(aes(colour = Population), size = 4, position = position_jitter(w = 0.3, h = 0)) +
  # add mean line
  stat_summary(fun= mean, fun.min=mean, fun.max=mean, geom="crossbar", width=0.5, linewidth=1,color="black") +
  # add error bars
  stat_summary(fun.data=mean_se, fun.args = list(mult=1), geom="errorbar", width=0.2, linewidth=1,color="black") +
  theme_classic()  +
  scale_color_manual(values = genotype_colors) +
  theme(legend.position = "none",
        text = element_text(size = 16),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 14)) +
  ylab("Normalized count") +
  ggtitle("MLGFLVLP")

  # save graph
  ggsave(paste0("MLGFLVLP","_pop_normalized_counts.png"),
         device="png",dpi="print",
         units = "in", width = 5, height = 3,
         path=paste0(subDir,"/NormCount-Graphs"))

```


### pretty plots

make a new table keeping only log2FC and padj for each genotyp

write a function to mini-fy each table


group1 or group2 = comparison from deseq you want to make mini

```{r get_deseq_results}

make_mini <- function(group1,group2,prefix="",keepmean=TRUE) {
  # group1 = "veA_wildtype_ctrl"
  # group2 = "veA_wildtype_TSA"
  # prefix = "veA_wildtype"
  temp <- as.data.frame(results(dds,
                                contrast=c("Origin", group1, group2),
                                alpha=0.05,
                                , independentFiltering=FALSE, cooksCutoff=TRUE))
  temp$ID <- row.names(temp)
  
  output <- temp[,c("ID","baseMean","log2FoldChange","padj")]
  colnames(output) <- c("ID","baseMean",
                        paste0(prefix,"_L2FC"),
                        paste0(prefix,"_padj"))
  
  # if specified above, do not keep the baseMean column
  if(keepmean==FALSE) {
    output <- output[,c("ID",
                        paste0(prefix,"_L2FC"),
                        paste0(prefix,"_padj"))]
  }
  
  return(output)
}

deseq_results <- make_mini("CA","EU","EU_vs_CA")
deseq_results$ID <- gsub("^[^-]+-|\\.m01$", "", deseq_results$ID )

# subset to include only msdins

```


heatmap, Violin plot, pca plot, and facet_wrap for all msdins
```{r pretty_heatmap}
# also make heatmap of genes with custom colors
genotype_colors <- c("#74121D","#af2930","#FE4A49",
                     "#03045e","#023e8a","#0077b6","#0096c7","#00b4d8","#48cae4","#90e0ef")

annotation_colors <- list(Population = setNames(genotype_colors, unique(df$Population)))

# Define your custom color scale (from dark blue to aqua)
my_colors <- colorRampPalette(c("grey90","#03045e"))(100)

# log transform count data
mat_log <- counts(dds, normalized=TRUE)[select,]
mat_log <- log10(mat_log)

top20 <- row.names(mat_log)
colnames(mat_log) <- metadata$Sample_ID

# remove the random prefix and suffixes
row.names(mat_log) <- gsub("^[^-]+-|\\.m01$", "", row.names(mat_log))
row.names(mat_log)

# remove log10(0) values that are -Inf
mat_log[mat_log == -Inf] <- 0

library(grid)


heatmap_plot <- pheatmap(mat_log, cluster_rows=FALSE, 
         show_rownames=TRUE,
         cluster_cols=TRUE,
         treeheight_col = 30,
         annotation_col=df,
         annotation_colors = annotation_colors,
         legend=TRUE,
         color=my_colors,
         legend_width = unit(0.2, "in"),
         legend_position = "right",
         border_color = "transparent")

gtable_obj <- heatmap_plot$gtable

# Modify the legend's vertical position
# Find the legend in the gtable and move it up
gtable_obj$grobs[[which(gtable_obj$layout$name == "legend")]]$grobs[[1]]$gp <- gpar(fontsize = 20)  # Set the font size to 10


# Modify the y position of the annotation_colors legend
# Adjust the y-coordinate to move the legend up
annotation_legend_index <- which(gtable_obj$layout$name == "annotation_legend")
gtable_obj$grobs[[annotation_legend_index]]$grobs[[1]]$gp <- gpar(fontsize = 20)  # Set the font size to 10



# Draw the modified heatmap with legend moved up
pdf(paste0(subDir,"/heatmap.pdf"), width = 8, height = 5, family="ArialMT")  # Specify desired width and height

grid.draw(gtable_obj)
dev.off()

# Transpose the matrix
mat_rotated <- t(mat_log)

pdf(paste0(subDir,"/heatmap_transposed.pdf"), width = 5, height = 8, family="ArialMT")  # Specify desired width and height

heatmap_plot<-pheatmap(mat_rotated, cluster_rows=TRUE, 
         show_rownames=TRUE,
         cluster_cols=FALSE,
         treeheight_col = 30,
         annotation_col=df,
         annotation_colors = annotation_colors,
         legend=TRUE,
         color=my_colors,
         legend_width = unit(0.2, "in"),
         legend_position = "right",
         border_color = "transparent")
gtable_obj <- heatmap_plot$gtable
grid.draw(gtable_obj)


dev.off()


```

```{r pretty_facets_vsd}

######### FACET_WRAP VSD COUNTS
# extract variance stabilized gene count data for all msdin genes

# list of all msdins
list

# generate facet_wrap for these samples

# extract data
mat2 <- as.data.frame(counts(dds,normalized=TRUE)[list,])
# log transform
mat2 <- log10(mat2)
# remove log10(0) values that are -Inf
mat2[mat2 == -Inf] <- 0
colnames(mat2) <- metadata$Sample_ID

# Reshape the data from wide to long format
library(tidyverse)
mat2_long <- mat2 %>%
  rownames_to_column("MSDIN") %>%        # Convert row names into a column
  pivot_longer(cols = -MSDIN,            # Pivot columns except for "Row"
               names_to = "Sample_ID",    # New column for column names
               values_to = "Value")    # New column for values

# add a new column to facet over:
# msdin type
msdin_type <- c("Canonical","Leaderless","Prolineless")
noncanonical <- c("MLGFLVLP","GPVFFAY")

# Add the "Type" column
mat2_long$Type <- ifelse(mat2_long$MSDIN %in% noncanonical, "Noncanonical", "Canonical")
mat2_long$Type <- ifelse(mat2_long$MSDIN %in% "MLGFLVLP", "Leaderless",mat2_long$Type)
mat2_long$Type <- ifelse(mat2_long$MSDIN %in% "GPVFFAY", "Prolineless",mat2_long$Type)

# add additional metadata:
# Population
metadata2 <- metadata[,c("Sample_ID","Population","Origin")]
mat2_long <- mat2_long %>%
  left_join(metadata2, by = "Sample_ID")

# set order
mat2_long$Origin <- factor(mat2_long$Origin, levels = c("CA",
                                                    "EU"))

mat2_long$Population <- factor(mat2_long$Population, levels = c("Drake",
                                                            "Pet",
                                                            "Picnic",
                                                            "Aso",
                                                            "Champ",
                                                            "Doc",
                                                            "Gron",
                                                            "Lamp",
                                                            "Quill",
                                                            "Tisza"))

# extract p values for each MSDIN
deseq_msdin <- deseq_results[list,]

subset(deseq_msdin,EU_vs_CA_L2FC > 1 & EU_vs_CA_padj < 0.05)[,1]
subset(deseq_msdin,EU_vs_CA_L2FC < -1 & EU_vs_CA_padj < 0.05)[,1]

# round p values
options(scipen = 999)

deseq_msdin$EU_vs_CA_padj <- signif(deseq_msdin$EU_vs_CA_padj, 3)
deseq_msdin$EU_vs_CA_padj <- formatC(deseq_msdin$EU_vs_CA_padj, format = "g", digits = 3)

colnames(deseq_msdin)[1] <-"MSDIN"
# merge this onto mat2_long
mat2_long <- merge(mat2_long,deseq_msdin,by="MSDIN",all.x=TRUE)
mat2_long$EU_vs_CA_padj <- as.numeric(mat2_long$EU_vs_CA_padj)

# now plot it and facet by MSDIN
pdf(paste0(subDir,"/log10_msdin.pdf"), width = 12, height = 12, family="ArialMT")  # Specify desired width and height

ggplot(data=mat2_long,aes(x=Origin,y=Value)) +
  geom_point(aes(colour = Population), size = 4, position = position_jitter(w = 0.3, h = 0)) +
  # add mean line
  stat_summary(fun= mean, fun.min=mean, fun.max=mean, geom="crossbar", width=0.5, linewidth=1,color="black") +
  # add error bars
  stat_summary(fun.data=mean_se, fun.args = list(mult=1), geom="errorbar", width=0.2, linewidth=1,color="black") +
  theme_classic()  +
  scale_color_manual(values = genotype_colors) +
  theme(legend.position = "none",
        text = element_text(size = 16),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) +
  ylab("Log10(normalized count)") +
  facet_wrap(Type~MSDIN)+
  # Add p-value labels on each facet
  geom_text(aes(x = 1.5, y = max(Value) * 0.9, label = sprintf("p = %.3f", EU_vs_CA_padj)), size = 5, color = "black", inherit.aes = FALSE)

dev.off()


```

```{r pretty_facets_norm}

# also do this with normalized counts
# extract data
mat3 <- as.data.frame(counts[list,])
colnames(mat3) <- metadata$Sample_ID

# Reshape the data from wide to long format
mat3_long <- mat3 %>%
  rownames_to_column("MSDIN") %>%        # Convert row names into a column
  pivot_longer(cols = -MSDIN,            # Pivot columns except for "Row"
               names_to = "Sample_ID",    # New column for column names
               values_to = "Value")    # New column for values

# add a new column to facet over:
# msdin type
msdin_type <- c("canonical","leaderless","prolineless")
noncanonical <- c("MLGFLVLP","GPVFFAY")

# Add the "Type" column
mat3_long$Type <- ifelse(mat3_long$MSDIN %in% noncanonical, "noncanonical", "canonical")
mat3_long$Type <- ifelse(mat3_long$MSDIN %in% "MLGFLVLP", "leaderless",mat3_long$Type)
mat3_long$Type <- ifelse(mat3_long$MSDIN %in% "GPVFFAY", "prolineless",mat3_long$Type)

# add additional metadata:
# Population
metadata2 <- metadata[,c("Sample_ID","Population","Origin")]
mat3_long <- mat3_long %>%
  left_join(metadata2, by = "Sample_ID")

# set order
mat3_long$Origin <- factor(mat3_long$Origin, levels = c("CA",
                                                    "EU"))

mat3_long$Population <- factor(mat3_long$Population, levels = c("Drake",
                                                            "Pet",
                                                            "Picnic",
                                                            "Aso",
                                                            "Champ",
                                                            "Doc",
                                                            "Gron",
                                                            "Lamp",
                                                            "Quill",
                                                            "Tisza"))



# now plot it and facet by MSDIN
pdf(paste0(subDir,"/normcount_msdin.pdf"), width = 12, height = 12, family="ArialMT")  # Specify desired width and height

ggplot(data=mat3_long,aes(x=Origin,y=Value)) +
  geom_point(aes(colour = Population), size = 4, position = position_jitter(w = 0.3, h = 0)) +
  # add mean line
  stat_summary(fun= mean, fun.min=mean, fun.max=mean, geom="crossbar", width=0.5, linewidth=1,color="black") +
  # add error bars
  stat_summary(fun.data=mean_se, fun.args = list(mult=1), geom="errorbar", width=0.2, linewidth=1,color="black") +
  theme_classic()  +
  scale_color_manual(values = genotype_colors) +
  theme(legend.position = "none",
        text = element_text(size = 16),
        strip.background = element_blank(),
        strip.text = element_text(face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) +
  ylab("Normalized count") +
  facet_wrap(~MSDIN, scales = "free_y")

dev.off()



```


```{r pretty_violin}
# adjust type names for the graph
mat2_long <- mat2_long %>%
  mutate(Type = recode(Type, 
                       "canonical" = "Canonical MSDINs", 
                       "prolineless" = "Prolineless GPVFFAY", 
                       "leaderless" = "Leaderless MLGFLVLP"))

genotype_colors <- c("#74121D","#af2930","#FE4A49",
                     "#03045e","#023e8a","#0077b6","#0096c7","#00b4d8","#48cae4","#90e0ef")


pdf(paste0(subDir,"/violin.pdf"), width = 4.5, height = 2.5, family="ArialMT")

ggplot(data=mat2_long,aes(x=Origin,y=Value,fill=Origin)) +
geom_violin(trim = FALSE, adjust = 0.6, draw_quantiles = c(0.25, 0.75), linetype = "dashed") +
  geom_violin(trim = FALSE, adjust = 0.6, draw_quantiles = 0.5, fill="transparent") +
  theme_classic()  +
  scale_fill_manual(values = c("#FE4A49", "#00b4d8")) +
  ylab("Log10(normalized count)") +
  #geom_hline(yintercept = 0, color = "black", linetype = "solid", size = 1) +  # Black line at y=0
  facet_wrap(~Type) +
  theme(panel.spacing = unit(0, "lines"),
        strip.background = element_blank(),
        strip.text = element_text(face = "bold"),
        legend.position = "none",
        text = element_text(color = "black",size = 10))

dev.off()

```

```{r pretty_pca}
##### PCA PLOT

pdf(paste0(subDir,"/pca.pdf"), width = 4.5, height = 2.5, family="ArialMT")  # Specify desired width and height

ggplot(pcaData,aes(x=PC1, y=PC2, color = Population, shape=Origin)) +
  geom_point(size=3) + 
  theme_classic() +
  scale_color_manual(values = genotype_colors) +
stat_ellipse(aes(group = Origin), colour = "black")+                 
  xlab(paste0("PC1 (",pc1var,"% variance)")) +
  ylab(paste0("PC2 (",pc2var,"% variance)")) +
  theme(panel.spacing = unit(0, "lines"),
        strip.background = element_blank(),
        text = element_text(color = "black",size = 10),
        legend.key.height = unit(0.15, 'in'))+ 
  guides(color = guide_legend(override.aes=list(shape = c(rep(16,3),rep(17,7)))))  # Customize shape of color legend


dev.off()


```


```{r pca_msdins_only}
# subset dds to only include msdins
# generate dds object
dds2 <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design = ~ Origin)


# keep only the msdins
list <- msdins$X4

# first see which of these genes have any counts at all

dds2 <- dds2[list,]

dds2 <- DESeq(dds2)

vsd2 <- varianceStabilizingTransformation(dds2, blind=FALSE)

# find distances between samples
sampleDists <- dist(t(assay(vsd2)))

# reformat distances
sampleDistMatrix <- as.matrix(sampleDists)

# make row and column names the same as sample IDs
rownames(sampleDistMatrix) <- rownames(df)
colnames(sampleDistMatrix) <- rownames(df)

# generate some nice colors
library(RColorBrewer)
colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255)

# plot it
library(pheatmap)
pheatmap(sampleDistMatrix,
         clustering_distance_rows=sampleDists,
         clustering_distance_cols=sampleDists,
         col=colors)

# next lets generate a PCA plot on variance stabilized data
vsd_out <- assay(vsd2)

# run PCA analysis
pca <- prcomp(t(vsd_out))

# plot scree
library(factoextra)
fviz_eig(pca)

# Create data frame with metadata and PC3 and PC4 values for input to ggplot
pcaData <- cbind(metadata[,c(2:5,8,13)], pca$x)

# Define color palette for genotypes
pcaData$Origin <- factor(pcaData$Origin, levels = c("CA",
                                                    "EU"))
# find percent variance for PC1 and PC2
# summary of variance
pcasummary <- summary(pca)
pcasummary
pc1var <- round(pcasummary$importance[2],digits = 4) * 100
pc2var <- round(pcasummary$importance[5],digits = 4) * 100
pc3var <- round(pcasummary$importance[8],digits = 4) * 100
pc4var <- round(pcasummary$importance[11],digits = 4) * 100


pcaData$Population <- factor(pcaData$Population, levels = c("Drake",
                                                            "Pet",
                                                            "Picnic",
                                                            "Aso",
                                                            "Champ",
                                                            "Doc",
                                                            "Gron",
                                                            "Lamp",
                                                            "Quill",
                                                            "Tisza"))



pdf(paste0(subDir,"/pca_msdins_only.pdf"), width = 4.5, height = 2.5, family="ArialMT")  # Specify desired width and height

ggplot(pcaData,aes(x=PC1, y=PC2, color = Population, shape=Origin)) +
  geom_point(size=3) + 
  theme_classic() +
  scale_color_manual(values = genotype_colors) +
stat_ellipse(aes(group = Origin), colour = "black")+                 
  xlab(paste0("PC1 (",pc1var,"% variance)")) +
  ylab(paste0("PC2 (",pc2var,"% variance)")) +
  theme(panel.spacing = unit(0, "lines"),
        strip.background = element_blank(),
        text = element_text(color = "black",size = 10),
        legend.key.height = unit(0.15, 'in'))+ 
  guides(color = guide_legend(override.aes=list(shape = c(rep(16,3),rep(17,7)))))  # Customize shape of color legend


dev.off()
```



```{r mapping_vs_counts}
# finally: also plot mapping rate for samples vs. counts for leaderless
dat <- read.csv("C:/Users/livia/Documents/02-drott-lab-files/leaderless_Aphalloides/Output_2025-02-20/NormCount-Graphs/Data/MLGFLVLP.csv")
colnames(dat)[1] <- "File_prefix"
mini_meta <- metadata[,c("File_prefix","perc_mapping")]
mini_meta2 <- metadata[,c("Sample_ID","perc_mapping")]

# merge
dat2 <- merge(dat,mini_meta,by="File_prefix",all.x=TRUE)

dat2$Origin <- factor(dat2$Origin, levels = c("CA",
                                                    "EU"))

dat2$Population <- factor(dat2$Population, levels = c("Drake",
                                                            "Pet",
                                                            "Picnic",
                                                            "Aso",
                                                            "Champ",
                                                            "Doc",
                                                            "Gron",
                                                            "Lamp",
                                                            "Quill",
                                                            "Tisza"))


library(ggplot2)

# Fit the linear model
# for all points:
lm_model <- lm(count ~ perc_mapping, data = dat2)

# based on origin:
ca <- subset(dat2,Origin == "CA")
eu <- subset(dat2,Origin == "EU")

lm_model_ca <- lm(count ~ perc_mapping, data = ca)
lm_model_eu <- lm(count ~ perc_mapping, data = eu)

eqn_ca <- substitute(italic(y) == a + b %.% italic(x) * "," ~~ italic(R)^2 ~ "=" ~ r2, 
                  list(a = as.numeric(format(coef(lm_model_ca)[1], digits = 3)),
                       b = as.numeric(format(coef(lm_model_ca)[2], digits = 3)),
                       r2 = format(summary(lm_model_ca)$r.squared, digits = 3)))

eqn_eu <- substitute(italic(y) == a + b %.% italic(x) * "," ~~ italic(R)^2 ~ "=" ~ r2, 
                  list(a = as.numeric(format(coef(lm_model_eu)[1], digits = 3)),
                       b = as.numeric(format(coef(lm_model_eu)[2], digits = 3)),
                       r2 = format(summary(lm_model_eu)$r.squared, digits = 3)))

# Extract coefficients and R-squared
eqn <- substitute(italic(y) == a + b %.% italic(x) * "," ~~ italic(R)^2 ~ "=" ~ r2, 
                  list(a = as.numeric(format(coef(lm_model)[1], digits = 3)),
                       b = as.numeric(format(coef(lm_model)[2], digits = 3)),
                       r2 = format(summary(lm_model)$r.squared, digits = 3)))

genotype_colors <- c("#74121D","#af2930","#FE4A49",
                     "#03045e","#023e8a","#0077b6","#0096c7","#00b4d8","#48cae4","#90e0ef")

ggplot(dat2, aes(x=perc_mapping,y=count,color=Population, shape=Origin)) +
  geom_point(size=3) +
  scale_color_manual(values = genotype_colors) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +  # Add linear regression line
  annotate("text", x = min(dat2$perc_mapping), y = max(dat2$count), 
           label = as.character(as.expression(eqn)), parse = TRUE, hjust = -0.3) +  # Add equation
  theme_classic()

ggsave("mapping_vs_leaderless_counts.png",
       path = subDir,
       units="in",
       width = 6, height = 5)

ggplot(dat2, aes(x=perc_mapping,y=count,color=Population, shape=Origin)) +
  geom_point(size=3) +
  scale_color_manual(values = genotype_colors) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +  # Add linear regression line
  annotate("text", x = min(dat2$perc_mapping), y = max(dat2$count), 
           label = as.character(as.expression(eqn_eu)), parse = TRUE, hjust = -0.3) +  # Add equation
  theme_classic()
ggsave("mapping_vs_leaderless_counts_EUlm.png",
       path = subDir,
       units="in",
       width = 6, height = 5)


ggplot(dat2, aes(x=perc_mapping,y=count,color=Population, shape=Origin)) +
  geom_point(size=3) +
  scale_color_manual(values = genotype_colors) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +  # Add linear regression line
  annotate("text", x = min(dat2$perc_mapping), y = max(dat2$count), 
           label = as.character(as.expression(eqn_ca)), parse = TRUE, hjust = -0.3) +  # Add equation
  theme_classic()

ggsave("mapping_vs_leaderless_counts_CAlm.png",
       path = subDir,
       units="in",
       width = 6, height = 5)

# also try log transformed counts...
mat2_long_ll <- merge(mat2_long_ll,mini_meta2,by="Sample_ID",all.x=TRUE)


ggplot(mat2_long_ll, aes(x=perc_mapping,y=Value,color=Population, shape=Origin)) +
  geom_point(size=3) +
  scale_color_manual(values = genotype_colors) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +  # Add linear regression line
  theme_classic()

lm_model <- lm(Value ~ perc_mapping, data = mat2_long_ll)
lm_model
# based on origin:
ca <- subset(mat2_long_ll,Origin == "CA")
eu <- subset(mat2_long_ll,Origin == "EU")

lm_model_ca <- lm(Value ~ perc_mapping, data = ca)
lm_model_eu <- lm(Value ~ perc_mapping, data = eu)

eqn_ca <- substitute(italic(y) == a + b %.% italic(x) * "," ~~ italic(R)^2 ~ "=" ~ r2, 
                  list(a = as.numeric(format(coef(lm_model_ca)[1], digits = 3)),
                       b = as.numeric(format(coef(lm_model_ca)[2], digits = 3)),
                       r2 = format(summary(lm_model_ca)$r.squared, digits = 3)))

eqn_eu <- substitute(italic(y) == a + b %.% italic(x) * "," ~~ italic(R)^2 ~ "=" ~ r2, 
                  list(a = as.numeric(format(coef(lm_model_eu)[1], digits = 3)),
                       b = as.numeric(format(coef(lm_model_eu)[2], digits = 3)),
                       r2 = format(summary(lm_model_eu)$r.squared, digits = 3)))

eqn
eqn_ca
eqn_eu
# Extract coefficients and R-squared
eqn <- substitute(italic(y) == a + b %.% italic(x) * "," ~~ italic(R)^2 ~ "=" ~ r2, 
                  list(a = as.numeric(format(coef(lm_model)[1], digits = 3)),
                       b = as.numeric(format(coef(lm_model)[2], digits = 3)),
                       r2 = format(summary(lm_model)$r.squared, digits = 3)))
```



Next let's figure out which genes are highly expressed...

```{r get_top_proteins}
library(rtracklayer)
library(Biostrings)
library(GenomicFeatures)

# Define file paths
genome_file <- "C:/Users/livia/Documents/02-drott-lab-files/aphalloides_reff/reff/10511_Aphal_PT_AllpathsLG_LINKS_jelly_pilon.fna"

# make sure chromosomes are assigned correctly
library(Rsamtools)

# Load Genome Sequence
genome_fa <- FaFile(genome_file)
class(genome)
names(genome)

# Load GFF3
head(gff_sorted)
gff <- "C:/Users/livia/Documents/02-drott-lab-files/leaderless_Aphalloides/aphal_reff_with_msdins.gff3"

colnames(gff_sorted) <- c("seqid", "source", "type", "start", "end", "score", "strand", "phase", "attributes")

sum(is.na(gff_sorted$start))  # Count missing start positions
sum(is.na(gff_sorted$end))

# Create TxDb from GFF3
options(scipen = 999)
txdb <- makeTxDbFromGFF(gff, format="gff3")
# save txdb object
saveDb(txdb, file = "txdb.sqlite")

# Extract CDS sequences from genome
transcripts <- exonsBy(txdb, by="tx", use.names=TRUE)

cds_seqs <- extractTranscriptSeqs(genome_fa, transcripts)

invalid_cds <- names(cds_seqs)[width(cds_seqs) %% 3 != 0]
invalid_cds

# Check for any invalid bases in the CDS sequences
invalid_bases <- grepl("[^ATCG]", as.character(cds_seqs))
invalid_seqs <- cds_seqs[invalid_bases]
invalid_seqs
# remove seqs with invalid bases
cds_seqs <- cds_seqs[!invalid_bases]

# Translate to protein sequences
protein_seqs <- translate(cds_seqs)

# extract protein seqs for names in the list of top 20 expressed genes 
protein_seqs_subset <- protein_seqs[names(protein_seqs) %in% top20]
protein_seqs_subset
# Write the protein sequences to a FASTA file
writeXStringSet(protein_seqs_subset, filepath = "top20_proteins.fasta")

# Write to a FASTA file
writeXStringSet(protein_seqs, "aphal_proteins.fasta")

cat("Protein sequences saved to proteins.fasta\n")


```

Now blast these seqs

### Star and Stringtie (WIP)

#### STAR installation

```{bash star_install, eval=FALSE}
# first tar aphal files
$ tar -xzvf aphalloides_reff.tar.gz

# next gzip the genome files
$ gzip -d 10511_Aphal_PT_AllpathsLG_LINKS_jelly_pilon.fna.gz
$ gzip -d t_5cc30df297ef2-5e76fa469d2f4-pasa_refine.gensas.gff3.gz

# check output
$ cd reff
$ ls
10511_Aphal_PT_AllpathsLG.LINKS.jelly.pilon_chrm_name_key
10511_Aphal_PT_AllpathsLG_LINKS_jelly_pilon.fna
leadered
leaderless
t_5cc30df297ef2-5e76fa469d2f4-pasa_refine.gensas.gff3

# I need to add the RIPPs from the leadered and leaderless foldes to the gff3.gz file. for now, skip this and try running star!
$ module load star
$ STAR --version
2.7.1a

# generate genome index for star
# using a basic slurm script
```


#### star_index_v1.sh

This ran very fast!

star_index job: 
Job ID: 31249642  
Cluster: agate  
User/Group: songs005/mdrott  
State: COMPLETED (exit code 0)  
Nodes: 1  
Cores per node: 8  
CPU Utilized: 00:02:33  
CPU Efficiency: 34.77% of 00:07:20 core-walltime  
Job Wall-clock time: 00:00:55  
Memory Utilized: 1.86 GB  
Memory Efficiency: 1.45% of 128.00 GB

```{bash star_index, eval=FALSE}
#!/bin/bash -l
#SBATCH --job-name=star_index   # Optional job name
#SBATCH --ntasks=1      # Total number of tasks
#SBATCH --cpus-per-task=8
#SBATCH --mem=128g      # max memory limit
#SBATCH --time=12:00:00   # Walltime limit
#SBATCH --mail-type=begin
#SBATCH --mail-type=end
#SBATCH --mail-user=songs005@umn.edu

# load star
module load star

# set dirs
genomedirectory="/scratch.global/songs005/aphal_rnaseq/reff"
fastqdirectory="/scratch.global/songs005/aphal_rnaseq/trimmed_data"

#########################
## STAR Generate Index ##
#########################

STAR --runThreadN 20 \
--runMode genomeGenerate \
--genomeDir $genomedirectory \
--genomeFastaFiles $genomedirectory/10511_Aphal_PT_AllpathsLG_LINKS_jelly_pilon.fna \
--sjdbGTFfile $genomedirectory/aphal_reff_with_msdins.gff3 \
--sjdbGTFtagExonParentTranscript Parent \
--genomeSAindexNbases 12 \
--sjdbOverhang 300
```



#### star_mapping_v1.sh

this is taking a long time to run so I am also trying hisat2.


```{bash star_mapping, eval=FALSE}
#!/bin/bash -l
#SBATCH --job-name=star_mapping  # Optional job name
#SBATCH --ntasks=1      # Total number of tasks
#SBATCH --cpus-per-task=8
#SBATCH --mem=128g      # max memory limit
#SBATCH --time=24:00:00   # Walltime limit
#SBATCH --mail-type=begin
#SBATCH --mail-type=end
#SBATCH --mail-user=songs005@umn.edu

# load star
module load star

# set dirs
genomedirectory="/scratch.global/songs005/aphal_rnaseq/reff"
fastqdirectory="/scratch.global/songs005/aphal_rnaseq/trimmed_data"
outdir="/scratch.global/songs005/aphal_rnaseq/star_output"

# make output dir
mkdir -p $outdir


#######################
## STAR Read mapping ##
#######################

ls $fastqdirectory/*.fastq.gz | awk -F '/' '{print $NF}' | awk -F '_trim_' '{print $1}' | sort | uniq | while read froot ; do
    STAR --genomeDir $genomedirectory \
    --runThreadN 20 \
    --readFilesIn $fastqdirectory/${froot}_trim_R1.fastq.gz $fastqdirectory/${froot}_trim_R2.fastq.gz \
    --readFilesCommand gunzip -c \
    --outFileNamePrefix $outdir/${froot} \
    --outSAMtype BAM SortedByCoordinate \
    --outSAMattributes Standard
done
```

UPDATE -- I need to use slurm arrays!

code fixed below with slurm arrays.

```{bash star_array, eval=FALSE}
#!/bin/bash -l
#SBATCH --job-name=star  # Optional job name
#SBATCH --ntasks=2      # Total number of tasks
#SBATCH --cpus-per-task=8
#SBATCH --mem=40g      # max memory limit
#SBATCH --time=30:00:00   # Walltime limit
#SBATCH --mail-type=begin
#SBATCH --mail-type=end
#SBATCH --mail-user=songs005@umn.edu
#SBATCH --array=1-39 # this will run one job for each sample

## This pulls from a tab-delimited file (array_config.txt) which has two columns. 
## First column is labeled ArrayTaskID, second is Sample as the header and first row
## array variable above indicates column 1 row labeled "10" which has a file ID prefix in column 2
## looks like:
## 10	Sample_ID

config=/scratch.global/songs005/aphal_rnaseq/reff/config.txt
sample=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $2}' $config)

# set dirs
genomedir="/scratch.global/songs005/aphal_rnaseq/reff"
fastqdir="/scratch.global/songs005/aphal_rnaseq/trimmed_data"
outdir="/scratch.global/songs005/aphal_rnaseq/star_output_msdins_array" # with hisat2 output

# make a specific dir for this job
mkdir -p $outdir
mkdir -p $outdir/$sample

# load star
module load star

#########################
## STAR Generate Index ##
#########################

STAR --runThreadN 20 \
--runMode genomeGenerate \
--genomeDir $genomedir \
--genomeFastaFiles $genomedir/10511_Aphal_PT_AllpathsLG_LINKS_jelly_pilon.fna \
--sjdbGTFfile $genomedir/aphal_reff_with_msdins.gff3 \
--sjdbGTFtagExonParentTranscript Parent \
--genomeSAindexNbases 9 \
--sjdbOverhang 300

STAR --genomeDir $genomedir \
--runThreadN 20 \
--readFilesIn $fastqdir/${sample}_trim_R1.fastq.gz $fastqdir/${sample}_trim_R2.fastq.gz \
--readFilesCommand gunzip -c \
--outFileNamePrefix $outdir/${sample}/${sample} \
--outSAMtype BAM SortedByCoordinate \
--outSAMattributes Standard \
--outSAMunmapped Within

# convert sam to bam format
# samtools view -uS $outdir/$sample/${sample}.sam | samtools sort -o $outdir/$sample/${sample}.bam

# index the bam
samtools index $outdir/$sample/${sample}Aligned.sortedByCoord.out.bam
```

```{bash star_array2, eval=FALSE}
#!/bin/bash -l
#SBATCH --job-name=star  # Optional job name
#SBATCH --ntasks=2      # Total number of tasks
#SBATCH --cpus-per-task=4
#SBATCH --mem=40g      # max memory limit
#SBATCH --time=1:00:00   # Walltime limit
#SBATCH --mail-type=begin
#SBATCH --mail-type=end
#SBATCH --mail-user=songs005@umn.edu
#SBATCH --array=1-39 # this will run one job for each sample

## This pulls from a tab-delimited file (array_config.txt) which has two columns. 
## First column is labeled ArrayTaskID, second is Sample as the header and first row
## array variable above indicates column 1 row labeled "10" which has a file ID prefix in column 2
## looks like:
## 10	Sample_ID

config=/scratch.global/songs005/aphal_rnaseq/reff/config.txt
sample=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $2}' $config)

# set dirs
genomedir="/scratch.global/songs005/aphal_rnaseq/reff"
fastqdir="/scratch.global/songs005/aphal_rnaseq/trimmed_data"
outdir="/scratch.global/songs005/aphal_rnaseq/hisat2_output_msdins" # with hisat2 output

# make a specific dir for this job
mkdir -p $outdir
mkdir -p $outdir/$sample

# load star
module load star

#########################
## STAR Generate Index ##
#########################

STAR --runThreadN 20 \
--runMode genomeGenerate \
--genomeDir $genomedir \
--genomeFastaFiles $genomedir/10511_Aphal_PT_AllpathsLG_LINKS_jelly_pilon.fna \
--sjdbGTFfile $genomedir/aphal_reff_with_msdins.gff3 \
--sjdbGTFtagExonParentTranscript Parent \
--genomeSAindexNbases 9 \
--sjdbOverhang 300

# convert sam to bam format
samtools view -uS $outdir/$sample/${sample}.sam | samtools sort -o $outdir/$sample/${sample}.bam
samtools index $outdir/$sample/${sample}.bam
```

```{bash install bbtools, eval=FALSE}
# module load conda and install bbtools
$ module load conda
$ conda activate subread_env

$ conda install agbiome::bbtools
$ conda list


```
### decontaminer.sh

```{bash run_decontaminer_unmapped, eval=FALSE}
#!/bin/bash -l
#SBATCH --job-name=decontaminer  # Optional job name
#SBATCH --ntasks=1      # Total number of tasks
#SBATCH --cpus-per-task=8
#SBATCH --mem=64g      # max memory limit
#SBATCH --time=6:00:00   # Walltime limit
#SBATCH --mail-type=begin
#SBATCH --mail-type=end
#SBATCH --mail-user=songs005@umn.edu
#SBATCH --array=1-39

config=/scratch.global/songs005/aphal_rnaseq/reff/config.txt
sample=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $2}' $config)


# set dirs
dir="/users/2/songs005/decontaMiner_1.4/shell_scripts"
fastqdir="/scratch.global/songs005/aphal_rnaseq/hisat2_output_msdins_array_unmapp"
outdir="/scratch.global/songs005/aphal_rnaseq/hisat2_output_msdins_array_decontaminer"

mkdir -p $outdir

# load modules
module load ncbi_blast
module load fastx_toolkit
module load samtools

# unzip unmapped read files
for file in $fastqdir/$sample/*.gz; do
    # Extract filename without extension
    filename=$(basename "$file" .gz)
    
    # Decompress and save as .fastq
    gunzip -c "$file" > "$fastqdir/$sample/$filename"
    
    echo "Extracted: $filename"
done

# run decontaminer
$dir/decontaMiner.sh -i $fastqdir/$sample \
-o $outdir/$sample \
-c /users/2/songs005/decontaMiner_1.4/config_files/configure.txt \
-F FASTQ \
-R n

# run filterblast
$dir/filterBlastInfo.sh -i $outdir/$sample/RESULTS/BACTERIA
$dir/filterBlastInfo.sh -i $outdir/$sample/RESULTS/FUNGI
$dir/filterBlastInfo.sh -i $outdir/$sample/RESULTS/VIRUSES

# collect info
$dir/collectInfo.sh -i $outdir/$sample/RESULTS/BACTERIA/COLLECTED_INFO/VALID
$dir/collectInfo.sh -i $outdir/$sample/RESULTS/FUNGI/COLLECTED_INFO/VALID
$dir/collectInfo.sh -i $outdir/$sample/RESULTS/VIRUSES/COLLECTED_INFO/VALID -V V

```

Start visualizing results
```{r visualize_decontaminer_r, eval=FALSE}
setwd("test_html/")
originaldata <- read.table("barPlotInfo_ge_CT_5_breast.txt",sep='\t', row.names=1, header=TRUE) ## should be data frame

newdata_1=subset(originaldata, select=c(1:10,22,23))

newdata_1=newdata_1[rowSums(newdata_1) >0.1 ,drop=FALSE, ] #take only those rows which are greater than zero

allsample_threshhold <- 1 ## Define threshold for average count > threshold

data_wt=newdata_1[(rowSums(newdata_1)/nrow(newdata_1))>= allsample_threshhold,drop=FALSE, ]
nor <- data_wt
data_wt <- as.data.frame(t(data_wt))

library(tidyverse)

library('dplyr') ##HAS COUNT FUNCTION

data_wt$Sample <-  row.names(data_wt)  
data_wt <- data_wt %>% 
  pivot_longer(!Sample, names_to = "Species", values_to = "count") # Gathering the columns to have normalized counts to a single column

## setting 2 different color variables

my_palette <- colorRampPalette(c("#179493","#76c286", "#ebdc96", "#ec9173","#d0587e"), alpha=TRUE)(n=20)
heat_colors <- brewer.pal(6, "Reds") ##"Greens"  ##"Blues"

ggplot(data_wt, aes(x = Sample, y = count, fill = Species)) + 
  geom_bar(stat = "identity")  + theme(axis.text.x = element_text(angle = 60, vjust = 1, hjust=1))

ggplot(data_wt, aes(x = Sample, y = count, fill = Species)) + 
  geom_col(position = "fill") +
  scale_y_continuous(labels = scales::percent)  + theme(axis.text.x = element_text(angle = 60, vjust = 1, hjust=1))


```

### Session info
```{r session_info}
sessionInfo()
```

